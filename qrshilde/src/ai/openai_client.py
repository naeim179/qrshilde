import os
from pathlib import Path
from dotenv import load_dotenv
import google.generativeai as genai
from groq import Groq

# ğŸ“Œ ØªØ­Ø¯ÙŠØ¯ Ù…Ø³Ø§Ø± Ø§Ù„Ø±ÙˆØª ÙˆØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
ROOT_DIR = Path(__file__).resolve().parents[3]
ENV_PATH = ROOT_DIR / ".env"
load_dotenv(dotenv_path=ENV_PATH)

def ai_enabled() -> bool:
    """
    Returns True if AT LEAST one API key is available.
    """
    has_gemini = os.getenv("GEMINI_API_KEY") is not None
    has_groq = os.getenv("GROQ_API_KEY") is not None
    return has_gemini or has_groq

def ask_gemini(prompt: str) -> str | None:
    """
    Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù…ÙˆØ¯ÙŠÙ„ Gemini
    """
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        return None  # Ø§Ù„Ù…ÙØªØ§Ø­ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ Ù†Ù†ØªÙ‚Ù„ Ù„Ù„ØªØ§Ù„ÙŠ

    try:
        genai.configure(api_key=api_key)
        
        # âœ… Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ù‡Ù†Ø§: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø¹Ø§Ù… ÙˆØ§Ù„Ù…Ø³ØªÙ‚Ø± Ù„Ù„Ø¨Ø§Ù‚Ø© Ø§Ù„Ù…Ø¬Ø§Ù†ÙŠØ©
        model = genai.GenerativeModel('gemini-flash-latest')
        
        # Ø¯Ù…Ø¬ ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… Ù…Ø¹ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª
        full_prompt = (
            "You are a cybersecurity expert analyzing a QR payload. "
            "Identify attacks, risks, and obfuscation. Be concise.\n"
            f"Payload to analyze: {prompt}"
        )
        
        response = model.generate_content(full_prompt)
        return response.text
    except Exception as e:
        print(f"[âš ï¸] Gemini Error: {e}")
        return None # ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ØŒ Ù†Ø±Ø¬Ø¹ None Ø¹Ø´Ø§Ù† Ù†Ø¬Ø±Ø¨ Groq

def ask_groq(prompt: str) -> str | None:
    """
    Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù…ÙˆØ¯ÙŠÙ„ Groq (Ø§Ø­ØªÙŠØ§Ø·ÙŠ)
    """
    api_key = os.getenv("GROQ_API_KEY")
    if not api_key:
        return None

    try:
        client = Groq(api_key=api_key)
        resp = client.chat.completions.create(
            model="llama-3.1-8b-instant",
            messages=[
                {
                    "role": "system",
                    "content": "You are a cybersecurity expert. Analyze this QR payload concisely."
                },
                {"role": "user", "content": prompt},
            ],
            temperature=0.2,
        )
        return resp.choices[0].message.content
    except Exception as e:
        print(f"[âš ï¸] Groq Error: {e}")
        return None

def ask_model(prompt: str) -> str | None:
    """
    Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø§Ù„Ø°ÙƒÙŠØ©:
    1. ØªØ­Ø§ÙˆÙ„ Gemini Ø£ÙˆÙ„Ø§Ù‹.
    2. Ø¥Ø°Ø§ ÙØ´Ù„ØŒ ØªØ­Ø§ÙˆÙ„ Groq.
    3. Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„Ø§Ø«Ù†Ø§Ù†ØŒ ØªØ¹ØªØ°Ø±.
    """
    # 1ï¸âƒ£ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: Google Gemini
    print("   [..] Trying Google Gemini...")
    result = ask_gemini(prompt)
    if result:
        return result

    # 2ï¸âƒ£ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©: Groq (Fallback)
    print("   [..] Gemini unavailable, switching to Groq...")
    result = ask_groq(prompt)
    if result:
        return result

    # 3ï¸âƒ£ Ø§Ù„ÙƒÙ„ ÙØ´Ù„
    print("[!] All AI models failed or keys are missing.")
    return None

def ask_model_safe(prompt: str):
    """
    Wrapper Ù„Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… ØªÙˆÙ‚Ù Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø¹Ù†Ø¯ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
    """
    try:
        result = ask_model(prompt)
        if result:
            return True, result
        else:
            return False, "AI Analysis unavailable (Check API keys or Quota)."
    except Exception as e:
        return False, str(e)